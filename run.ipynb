{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import picamera\n",
    "import picamera.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "text = widgets.Text(\n",
    "    value='Hello World',\n",
    "    placeholder='Type something',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frame(frame):\n",
    "    img = Image.fromarray(frame, 'RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    img_array_extended = np.expand_dims(img_array, axis=0).astype('float32')\n",
    "    processed = keras.applications.mobilenet.preprocess_input(img_array_extended)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "# model.save('my_model.h5')\n",
    "\n",
    "# # Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "model = load_model('shape-detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paho.mqtt.client.MQTTMessageInfo at 0x562dc600>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "mqttc = mqtt.Client()\n",
    "mqttc.connect(\"mqtt.cmmc.io\", 1883, 60)\n",
    "# mqttc.publish(\"CMMC/PLUG-001/$/command\", \"OFF\")\n",
    "# mqttc.publish(\"CMMC/PLUG-001/$/command\", \"ON\")\n",
    "\n",
    "mqttc2 = mqtt.Client()\n",
    "mqttc2.connect(\"localhost\", 1883, 60)\n",
    "mqttc2.publish(\"KBML/class\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mqttc2.publish(\"lamp\", \"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mqttc2.publish(\"lamp\", \"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566974ffd43d46aaa5d3fce641fcf098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Hello World', description='String:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5917d13912c457f9ffcc6f342dc5131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-64a08c5a7a80>\", line 49, in <module>\n",
      "    prediction = model.predict(processed_image)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\", line 3292, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1458, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 671, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 714, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 683, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 668, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.5/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# from __future__ import print_function\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from picamera.array import PiRGBArray\n",
    "from picamera import PiCamera\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "from imutils.video import FPS\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "#image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "#camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "# initialize the camera and stream\n",
    "camera = PiCamera()\n",
    "# camera.resolution = (320, 240)\n",
    "camera.framerate = 32\n",
    "camera.resolution = (224, 224)\n",
    "camera.rotation = (270)\n",
    "camera.start_preview()\n",
    "# rawCapture = PiRGBArray(camera, size=(320, 240))\n",
    "rawCapture = PiRGBArray(camera)\n",
    "stream = camera.capture_continuous(rawCapture, format=\"bgr\",use_video_port=True)\n",
    "\n",
    "image_widget = widgets.Image()\n",
    "display(text)\n",
    "display(image_widget)\n",
    "\n",
    "\n",
    "for (i, f) in enumerate(stream):\n",
    "    frame = f.array\n",
    "    image_widget.value =  bgr8_to_jpeg(frame)\n",
    "    processed_image = prepare_frame(frame)  # prepare frame\n",
    "    t1 = datetime.datetime.now()\n",
    "    prediction = model.predict(processed_image)\n",
    "    t2 = datetime.datetime.now()\n",
    "    result = np.argmax(prediction)  # imagenet_utils.decode_predictions(prediction)\n",
    "    text.value = \"class=\" + str(result)\n",
    "    \n",
    "    if str(result) == \"0\":\n",
    "        mqttc2.publish(\"KBML/class\", \"0\")      \n",
    "    elif str(result) == \"1\":\n",
    "        mqttc2.publish(\"KBML/class\", \"1\") \n",
    "    elif str(result) == \"2\":\n",
    "        mqttc2.publish(\"KBML/class\", \"2\")\n",
    "    elif str(result) == \"3\":\n",
    "        mqttc2.publish(\"KBML/class\", \"3\")\n",
    "        \n",
    "#         mqttc.publish(\"CMMC/PLUG-001/$/command\", \"OFF\")\n",
    "#         mqttc.publish(\"CMMC/PLUG-002/$/command\", \"OFF\")    \n",
    "    rawCapture.truncate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
